---
title: "Problem1"
output: html_document
---




#### (a) Entropy of the dataset

Entropy formula

\(H = - \sum(\pi log(\pi))\)

entropy of dataset: 0.8812909

#### (b) Information Gain of all possible split

All possible split, by age, education and occupation

![]((b).png)

Information Gain formula $$\frac{H(Class) + H(Attribute) - H(Class, Attribute)}{H(Attribute)}$$

classifier 

1. $age\leq40$ : 0.3958156
2. $education$: 0.3303134
3. $occupation$: 0.2812909

#### (c)  First split? resulting decision tree? accuracy?

Classifier $age\leq40$ gains the most, so it should be the first split

Decision tree:

![]((c).png)

Accuracy of classifier


$0.5*0.6+0.5*1 = 0.8$

#### (d) Which split for second layer? accuracy?

Classifier $education$ would be the second pick according to GI

Accuracy of classifier

$0.4*1+0.3*(1/3)+0.3*(2/3)=0.7$

#### (e) Repeat by GINI

Replace by GINI

  $age \leq 40$: 0.24
     
  $education$: 0.2666667
     
  $occupation$: 0.4
  
Lower GINI means better split, so $age \leq 40$ should be the first and followed by $education$.